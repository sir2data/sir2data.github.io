<!DOCTYPE html>
<html lang="en"><head>
<meta http-equiv="content-type" content="text/html; charset=UTF-8">

  <!-- Basic Page Needs
  –––––––––––––––––––––––––––––––––––––––––––––––––– -->
  <meta charset="utf-8">
  <title>Benchmarking Single image reflection removal algorithms </title>
  <meta name="description" content="">
  <meta name="author" content="">

  <!-- Mobile Specific Metas
  –––––––––––––––––––––––––––––––––––––––––––––––––– -->
  <meta name="viewport" content="width=device-width, initial-scale=1">

  <!-- FONT
  –––––––––––––––––––––––––––––––––––––––––––––––––– -->
  <link href="SceneNN%20%20A%20Scene%20Meshes%20Dataset%20with%20aNNotations_files/css.css" rel="stylesheet" type="text/css">

  <!-- CSS
  –––––––––––––––––––––––––––––––––––––––––––––––––– -->
  <link rel="stylesheet" href="Benchmarking_Singlae_image_reflection_removal_algorithms_files/normalize.css">
  <link rel="stylesheet" href="Benchmarking_Singlae_image_reflection_removal_algorithms_files/skeleton.css">
  <link rel="stylesheet" href="Benchmarking_Singlae_image_reflection_removal_algorithms_files/scenenn.css">

  <!-- Favicon
  –––––––––––––––––––––––––––––––––––––––––––––––––– -->
  <link rel="icon" type="image/png" href="http://people.sutd.edu.sg/%7Esaikit/projects/sceneNN/images/favicon.png">

  <!-- Google icon
  -------------------------------------------------- -->
  <link rel="stylesheet" href="Benchmarking_Singlae_image_reflection_removal_algorithms_files/icon.css">

  <!-- jQuery
  -------------------------------------------------- -->
  <script src="Benchmarking_Singlae_image_reflection_removal_algorithms_files/analytics.js" async=""></script><script src="Benchmarking_Singlae_image_reflection_removal_algorithms_files/jquery.js"></script>

  <!-- Analytics
  -------------------------------------------------- -->
  <script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');
  ga('create', 'UA-86869673-1', 'auto');
  ga('send', 'pageview');
  </script>

  <!-- Hover effect: https://codepen.io/nxworld/pen/ZYNOBZ -->
  <style>
    img {
        display: block;
    }
    figure {
        padding: 0;
        margin: 0;
        overflow: hidden;
        cursor: pointer;
    }
    .hover figure img {
        -webkit-transform: rotate(0) scale(1);
        transform: rotate(0) scale(1);

    }
    .hover figure:hover img {
        -webkit-transition: .3s ease-in-out;
        transition: .3s ease-in-out;
        -webkit-transform: rotate(15deg) scale(1.4);
        transform: rotate(15deg) scale(1.4);
    }
  </style>

  <!-- WebGL
  --------------------------------------------------- -->
  <script src="Benchmarking_Singlae_image_reflection_removal_algorithms_files/three.js"></script>
  <script src="Benchmarking_Singlae_image_reflection_removal_algorithms_files/PLYLoader.js"></script>
  <script src="Benchmarking_Singlae_image_reflection_removal_algorithms_files/Detector.js"></script>
  <script src="Benchmarking_Singlae_image_reflection_removal_algorithms_files/stats.js"></script>
  <script src="Benchmarking_Singlae_image_reflection_removal_algorithms_files/XMLLoader.js"></script>
  <script src="Benchmarking_Singlae_image_reflection_removal_algorithms_files/OrbitControls.js"></script>

  <script>
    if ( ! Detector.webgl ) Detector.addGetWebGLMessage();

    var container, stats;
    var camera, cameraTarget, scene, renderer, controls;

    function show_webgl(ply_name, xml_name) {
        init(ply_name, xml_name);
        animate();
    }

    function hide_webgl() {
        $("#glcanvas").empty();
        scene = undefined;
        renderer = undefined;
    }

    // Get ply_name and xml_name from URL
    function getQueryVariable(variable)
    {
        var query = window.location.search.substring(1);
        var vars = query.split("&");
        for (var i=0;i<vars.length;i++) {
            var pair = vars[i].split("=");
            if(pair[0] == variable){
                return pair[1];
            }
        }
        return(false);
    }

    function init(ply_name, xml_name) {
            var teaser = $("#glcanvas");

            // Before emptying the teaser div, keep its size for the renderer
            var divWidth = teaser.width();
            var divHeight = teaser.height();
            teaser.empty();

            container = teaser[0]; // document.getElementById( 'teaser' );

            //document.body.appendChild( container );

            camera = new THREE.PerspectiveCamera( 45, window.innerWidth / window.innerHeight, 0.1, 100 );
            camera.position.set( 0, 3, 5 );

            cameraTarget = new THREE.Vector3( 0, -0.25, 0 );

            scene = new THREE.Scene();


            // Ground

//               var plane = new THREE.Mesh(
//                                           new THREE.PlaneBufferGeometry( 40, 40 ),
//                                           new THREE.MeshPhongMaterial( { color: 0x999999, specular: 0x101010 } )
//                                           );
//               plane.rotation.x = -Math.PI/2;
//               plane.position.y = -1.2;
//               scene.add( plane );
//
//               plane.receiveShadow = true;

             // Load the PLY file
            console.log(ply_name);
            var loader = new THREE.PLYLoader();
            loader.load( ply_name, function ( geometry ) {

               // for smooth shading, use vertex normals
               geometry.computeVertexNormals();

               //var material = new THREE.MeshStandardMaterial( { color: 0x0055ff } );
               //var material = new THREE.MeshStandardMaterial({vertexColors: THREE.VertexColors});
               var material = new THREE.MeshLambertMaterial( {vertexColors: THREE.VertexColors} );
               var mesh = new THREE.Mesh( geometry, material );

               mesh.position.y = - 0.95;
               //mesh.position.x = -0.65;
               mesh.rotation.y = -Math.PI / 7.4;
               //mesh.rotation.x = 0; //- Math.PI / 2;
               //mesh.rotation.z = Math.PI / 2;
               //mesh.scale.multiplyScalar( 1.0 );

               mesh.castShadow = true;
               mesh.receiveShadow = true;

               scene.add( mesh );

            });

            // Load the XML file
            console.log(xml_name);
            var loader2 = new THREE.XMLLoader();
            loader2.load( xml_name, function ( geometry2 ) {

                //geometry2.computeFaceNormals();

                var material2 = new THREE.LineBasicMaterial( {vertexColors: THREE.VertexColors, linewidth: 2} );
                var line = new THREE.Line( geometry2[0], material2, THREE.LinePieces );

                line.position.y = - 0.95;
                // mesh.position.x = -0.65;
                //line.rotation.y = Math.PI / 7.4;           //the bug is here !!!
                //line.rotation.x = 0; //- Math.PI / 2;
                //line.rotation.z = Math.PI / 2;
                //line.scale.multiplyScalar( 1.0 );

                //line.castShadow = true;
                //line.receiveShadow = true;
                scene.add( line );

                // add the text for each aabbox
                if(geometry2[1].length >= 1) {
                    //console.log(geometry2[1][0]);
                    for(var n=0; n<geometry2[1].length; n++)
                    {
                        scene.add(geometry2[1][n]);
                    }
                }

            } );

           // Lights

           //scene.add( new THREE.HemisphereLight( 0x443333, 0x111122 ) );
           //scene.add( new THREE.HemisphereLight( 0xffffff, 0xffffff ) );

           addAmbientLight( 0xffffff, 0.2 );
           addShadowedLight( 2, 3, 2, 0xffffff, 1 );
           //addShadowedLight( 2, 3, -2, 0xffffff, 1 );

//               var light1 = new THREE.PointLight(0xffffff);
//               light1.position.set(0,25,0);
//               scene.add(light1);

           // renderer
           renderer = new THREE.WebGLRenderer( { antialias: true } );
           renderer.setClearColor( 0xdddddd );
           renderer.setPixelRatio( window.devicePixelRatio );
           renderer.setSize( divWidth, divHeight );

           renderer.gammaInput = true;
           renderer.gammaOutput = true;

           renderer.shadowMap.enabled = false;
           renderer.shadowMap.renderReverseSided = false;

           container.appendChild( renderer.domElement );

            // controls
           controls = new THREE.OrbitControls( camera, renderer.domElement );

           // stats

           //stats = new Stats();
//                stats.domElement.style.position = 'absolute';
//                stats.domElement.style.bottom = '0px';
//                stats.domElement.style.zIndex = 100;
           //container.appendChild( stats.dom );

           // resize

           window.addEventListener( 'resize', onWindowResize, false );

    }


    function addShadowedLight( x, y, z, color, intensity ) {


        var directionalLight = new THREE.DirectionalLight( color, intensity );
        directionalLight.position.set( x, y, z );
        scene.add( directionalLight );

        directionalLight.castShadow = true;

        var d = 1;
        directionalLight.shadow.camera.left = -d;
        directionalLight.shadow.camera.right = d;
        directionalLight.shadow.camera.top = d;
        directionalLight.shadow.camera.bottom = -d;

        directionalLight.shadow.camera.near = 0.2;
        directionalLight.shadow.camera.far = 15;

        directionalLight.shadow.mapSize.width = 512;
        directionalLight.shadow.mapSize.height = 512;

        directionalLight.shadow.bias = -0.005;


    }
    function addAmbientLight(color, intensity) {
        var ambientLight = new THREE.AmbientLight(color, intensity);
        scene.add( ambientLight );
    }

    function onWindowResize() {

        var teaser = $("#glcanvas");
        var divWidth = teaser.width();
        var divHeight = teaser.height();

        camera.aspect = divWidth / divHeight;
        camera.updateProjectionMatrix();

        renderer.setSize( divWidth, divHeight );

    }

    function animate() {

        // We set renderer to undefined when popup dialog is hidden.
        if (renderer == undefined) return;

        requestAnimationFrame( animate );

        render();
        controls.update();
        //stats.update();

    }

    function render() {

        //var timer = Date.now() * 0.0005;
        //camera.position.x = Math.sin( timer ) * 3;
        //camera.position.z = Math.cos( timer ) * 3;

        // camera.lookAt( cameraTarget );
        camera.lookAt(scene.position);

        renderer.render( scene, camera );

    }
  </script>

<script data-timestamp="1500602677994" src="SceneNN%20%20A%20Scene%20Meshes%20Dataset%20with%20aNNotations_files/embed.js"></script><link href="SceneNN%20%20A%20Scene%20Meshes%20Dataset%20with%20aNNotations_files/a_data/lounge.css" rel="prefetch"><link href="SceneNN%20%20A%20Scene%20Meshes%20Dataset%20with%20aNNotations_files/a_data/common.js" rel="prefetch"><link href="SceneNN%20%20A%20Scene%20Meshes%20Dataset%20with%20aNNotations_files/a_data/lounge_002.js" rel="prefetch"><link href="SceneNN%20%20A%20Scene%20Meshes%20Dataset%20with%20aNNotations_files/a_data/config.js" rel="prefetch"></head>
<body>

  <!-- Primary Page Layout
  –––––––––––––––––––––––––––––––––––––––––––––––––– -->
  <div class="container">


        <h4><center> Benchmarking Single-Image Reflection Removal Algorithms</p></center></h4>

        <center><p style="margin-bottom:12px;">Renjie Wan</a><sup>1</sup>, <a class="simple" href="http://www.shiboxin.com">Boxin Shi</a><sup>2</sup>, Ling-Yu Duan</a><sup>3</sup>, Ah-Hwee Tan<sup>1</sup>, and <a class="simple" href="http://www.ntu.edu.sg/home/eackot/">Alex C. Kot</a><sup>1</sup></p></center>

        <p style="margin-bottom:20px;">
        <sup>1</sup>Nanyang Technological University
        <span style="display:inline-block; width: 32px"></span>
        <sup>2</sup>National Institute of Advanced Industrial Science and Technology
        <span style="display:inline-block; width: 32px"></span>
        <sup>3</sup>Peking University
        </p>

        <!--<img src="images/overview.png" class="u-max-full-width"></img>-->
        <!--<iframe width="100%" height="500px" scrolling="no" style="border:0" src="overview.html"></iframe>-->
        <div id="teaser" class="container" style="width:100%; margin:0; padding:0"><div class="row" style="padding-bottom: 1%;"><div class="three columns hover" style="margin-left: 1%;"><figure><img id="076" class="u-max-full-width" src="SceneNN%20%20A%20Scene%20Meshes%20Dataset%20with%20aNNotations_files/076_segmented.png" data-popup-open="popup-1"></figure></div><div class="three columns hover" style="margin-left: 1%;"><figure><img id="086" class="u-max-full-width" src="SceneNN%20%20A%20Scene%20Meshes%20Dataset%20with%20aNNotations_files/086_segmented.png" data-popup-open="popup-1"></figure></div><div class="three columns hover" style="margin-left: 1%;"><figure><img id="032" class="u-max-full-width" src="SceneNN%20%20A%20Scene%20Meshes%20Dataset%20with%20aNNotations_files/032_segmented.png" data-popup-open="popup-1"></figure></div><div class="three columns hover" style="margin-left: 1%;"><figure><img id="082" class="u-max-full-width" src="SceneNN%20%20A%20Scene%20Meshes%20Dataset%20with%20aNNotations_files/082_segmented.png" data-popup-open="popup-1"></figure></div></div><div class="row" style="padding-bottom: 1%;"><div class="three columns hover" style="margin-left: 1%;"><figure><img id="049" class="u-max-full-width" src="SceneNN%20%20A%20Scene%20Meshes%20Dataset%20with%20aNNotations_files/049_segmented.png" data-popup-open="popup-1"></figure></div><div class="three columns hover" style="margin-left: 1%;"><figure><img id="093" class="u-max-full-width" src="SceneNN%20%20A%20Scene%20Meshes%20Dataset%20with%20aNNotations_files/093_segmented.png" data-popup-open="popup-1"></figure></div><div class="three columns hover" style="margin-left: 1%;"><figure><img id="246" class="u-max-full-width" src="SceneNN%20%20A%20Scene%20Meshes%20Dataset%20with%20aNNotations_files/246_segmented.png" data-popup-open="popup-1"></figure></div><div class="three columns hover" style="margin-left: 1%;"><figure><img id="021" class="u-max-full-width" src="SceneNN%20%20A%20Scene%20Meshes%20Dataset%20with%20aNNotations_files/021_segmented.png" data-popup-open="popup-1"></figure></div></div><div class="row" style="padding-bottom: 1%;"><div class="three columns hover" style="margin-left: 1%;"><figure><img id="207" class="u-max-full-width" src="SceneNN%20%20A%20Scene%20Meshes%20Dataset%20with%20aNNotations_files/207_segmented.png" data-popup-open="popup-1"></figure></div><div class="three columns hover" style="margin-left: 1%;"><figure><img id="213" class="u-max-full-width" src="SceneNN%20%20A%20Scene%20Meshes%20Dataset%20with%20aNNotations_files/213_segmented.png" data-popup-open="popup-1"></figure></div><div class="three columns hover" style="margin-left: 1%;"><figure><img id="272" class="u-max-full-width" src="SceneNN%20%20A%20Scene%20Meshes%20Dataset%20with%20aNNotations_files/272_segmented.png" data-popup-open="popup-1"></figure></div><div class="three columns hover" style="margin-left: 1%;"><figure><img id="074" class="u-max-full-width" src="SceneNN%20%20A%20Scene%20Meshes%20Dataset%20with%20aNNotations_files/074_segmented.png" data-popup-open="popup-1"></figure></div></div></div>

        <!-- WebGL -->
        <div class="popup" data-popup="popup-1" data-popup-close="popup-1">
            <div class="popup-inner">
                <a class="popup-close" data-popup-close="popup-1" href="#">x</a>
                <div id="glcanvas" style="width:100%; height:100%">
                    <!-- reserved space -->
                </div>
            </div>
        </div>

        <p>We propose the `SingleR<sup>2</sup>' benchmark dataset with a large number and a great diversity of mixture images, and ground truth of background and reflection.
        Our dataset includes the controlled scenes taken indoor and wild scenes taken outdoor.
        <p>
		One part of the controlled scene is composed by a set of solid objects, which uses commonly available daily-life objects (<I>e.g.</I> ceramix mugs, plush toys, fruits, <I>etc</I>.) for both the background and the reflected scenes.
		The other parts of the controlled scenes use five different postcards and combines them in a pair-wise manner by using each card as background  and reflection, respectively.
        <p>
		The wild scenes are with real-world objects of complex reflectance (car, tree leaves, glass windows, <I>etc</I>), various distances and scales (residential halls, gardens, and lecture room, <I>etc</I>),
		and different illuminations (direct sunlight, cloudy sky light and twilight, <I>etc</I>.).
        </p>

        <!-- ------------------------------------- -->

        <div class="section">
            <h5>News</h5>

            <ul class="news">

            <li><b>July 21, 2017</b>: The webpage is online now. The dataset will come soon!</li>
            </ul>
        </div>

        <!-- ------------------------------------- -->

        <div class="section">
            <h5>Dataset &amp; Tools</h5>

            <div class="container">
			<center>
              <div class="row">
                <div class="three columns">
                    <i class="material-icons grey-icon">cloud</i>
                    <br>
                    <a>Dataset</a>
                    <br>

                </div>

                <div class="three columns">
                    <i class="material-icons grey-icon">cloud_download</i>
                    <br>
                    <a>Download script</a>
                    <br>
                </div>

                <div class="three columns">
                    <i class="material-icons grey-icon">create</i>
					<br>
                    <a>Annotation tool</a>
                    <br>
                </div>

              </div>
			  </center>
            </div>

            <br>
			
			          <ul>


            <!--
            <li>
            A customized version of moving volume KinectFusion to generate input for the reconstruction pipeline (available soon)
            </li>

            <li>
            A customized version of NiViewer for RGBD data capture from Asus Xtion (available soon).
            </li>

            <li>
            An experimental application for RGBD data capture from Microsoft Kinect v2 (available soon).
            </li>
            -->


            </ul>
        </div>

        <!-- ------------------------------------- -->

        <div class="section publication">
            <h5>Publication</h5>
            <ul>
            <li>
                <div>
                <p class="paper title">Benchmarking Single-Image Reflection Removal Algorithms</p>
                <p>Renjie Wan, Boxin Shi, Ling-Yu Duan, Ah-Hwee Tan, and Alex C. Kot</p>
                <p class="paper venue">International Conference on Computer Vision 2017.</p>
                <a>Paper</a>
                <a>Supplemental</a>
                <a>Slides</a>
                <a>Poster</a>
                <a id="abibSceneNN" href="#">Bibtex</a>
                </div>
<!-- Don't indent this for correct bibtex display -->
<pre style="display: none;" id="bibSceneNN"><code>@inproceedings{SIR2-iccv17,
    author = {Renjie Wan and Boxin Shi and Ling-Yu Duan and Ah-Hwee Tan and Alex C. Kot},
    title = {Benchmarking Single-Image Reflection Removal Algorithms},
    booktitle = {International Conference on Computer Vision (ICCV)},
    year = {2017}
}</code>
</pre>
</div>
        <div class="section">
            <h5>Discussion</h5>
            <p>
            Please email us at <b><u>wanpeoplejie [at] gmail.com</u></b> for any inquiries.
            </p>
        </div>


        <!-- ------------------------------------- -->

        <div class="section">
            <h5>Call for Contributions</h5>

            <p>If you find this dataset useful and would like to 
contribute, please do not hesitate to let us know. Below are some 
potential ideas that you can help with to expand the dataset:
            </p><ul>
                <li>Capture new scenes and contribute raw RGB-D videos.</li>
                <li>Refine annotation of existing scenes.</li>
                <li>Annotate scenes from other datasets (<a href="http://cs.nyu.edu/%7Esilberman/datasets/nyu_depth_v2.html">NYU Depth v2</a>, <a href="http://sun3d.cs.princeton.edu/">SUN3D</a>) with our annotation tool.
                </li><li>Reconstruct the difficult scenes into higher quality.</li>
            </ul>
            <p></p>
        </div>

        <!-- ------------------------------------- -->

        <div class="section">
            <h5>Acknowledgements</h5>
            <p>
            We are grateful to the anonymous reviewers for their 
constructive comments.
            We also thank other related people for thier assistances with the data capture.
            </p>

            <p>
            This research is supported by the National Research Foundation, Prime Minister’s Office, Singapore, under the NRF-NSFC grant NRF2016NRF-NSFC001-098.  The research work was done at the <a href="http://rose.ntu.edu.sg/Pages/Home.aspx"> Rapid-Rich Object Search (ROSE) Lab </a>, Nanyang Technological University, Singapore.
Boxin Shi is supported by a project commissioned by the New Energy and
Industrial Technology Development Organization (NEDO). This work was partially supported by grants from National Natural Science Foundation of China (U1611461, 61661146005).
            </p>

        </div>
  </div>

  <script>
    function show_scene_list() {
        // Populate teaser images (a 3x4 grid of images)
        var height = 3;
        var width = 4;

        // Change the scene ID here for other scenes
        var images = ["076", 		"086",		"032",		"082",
                      "049", 		"093",		"246",		"021",
                      "207", 		"213",		"272",		"074"];

        $("#teaser").empty();
        for (var i = 0; i < height; ++i) {
            var row = "<div class=\"row\" style=\"padding-bottom: 1%;\">";
            for (var j = 0; j < width; ++j) {
                var id = images[i * width + j];
                var file = "images/scenes/" + id + "/" + id + "_segmented.png";
                row += "<div class=\"three columns hover\" style='margin-left: 1%;'>";
                // Change margin above to adjust gaps between columns
                row += "<figure><img id=\"" + id + "\" class=\"u-max-full-width\" src=\"" + file + "\" data-popup-open=\"popup-1\"></img></figure>";
                row += "</div>";
            }
            row += "</div>"

            $("#teaser").append(row);
        }

        // Add click event for each image
        /*
        for (var i = 0; i < height; ++i) {
            for (var j = 0; j < width; ++j) {
                var id = images[i * width + j];
                $("#"+id).click(function(e) {
                    //window.location.href = "load_ply.html?ply_name=data/066_merge_color_lowres.ply&xml_name=data/066_merge_correct.xml";

                    // test scene
                    show_webgl("data/066_merge_color_lowres.ply",
                                "data/066_merge_correct.xml");
                });
            }
        }*/
    }

    $(document).ready(function(){
        var bibName = ["SceneNN", "Tool"];

        // Add click event for bibtex links
        for (var i = 0; i < bibName.length; ++i) {
            $("#abib" + bibName[i]).click(function(e){

                var abib = event.target.id; // <a> that fires the event
                var bib = abib.replace("abib", "bib");

                $("#"+bib).toggle(100);

                // Scroll to the code position
                $('html, body').animate({
                    scrollTop: $("#"+bib).offset().top
                }, 100);

                // Cancel the default action (jump to page top due to link clicked)
                e.preventDefault();
            });

            // Hide at start
            $("#bib" + bibName[i]).hide();
        }

        show_scene_list();

        // Pop-up dialog for WebGL
        //----- OPEN'

        $('[data-popup-open]').on('click', function(e)  {
            var targeted_popup_class = jQuery(this).attr('data-popup-open');
            $('[data-popup="' + targeted_popup_class + '"]').fadeIn(350);

            // show WebGL
            show_webgl("data/066_merge_color_lowres.ply",
                       "data/066_merge_correct.xml");

            e.preventDefault();
        });

        //----- CLOSE
        $('[data-popup-close]').on('click', function(e)  {
            // if clicked on a child element, don't close.
            if (e.target !== this) return;

            var targeted_popup_class = jQuery(this).attr('data-popup-close');
            $('[data-popup="' + targeted_popup_class + '"]').fadeOut(350);

            // hide WebGL
            hide_webgl();

            e.preventDefault();
        });

        // When video is hovered, show the controls
        $('#my-video').hover(function() {
            if (this.hasAttribute("controls")) {
                this.removeAttribute("controls")
            } else {
                this.setAttribute("controls", "controls")
            }
        });
    });
  </script>

  <!-- Disqus comment count
  -------------------------------------------------- -->
  <script id="dsq-count-scr" src="SceneNN%20%20A%20Scene%20Meshes%20Dataset%20with%20aNNotations_files/count.js" async=""></script>

  <!-- End Document
  –––––––––––––––––––––––––––––––––––––––––––––––––– -->


<iframe style="display: none;"></iframe></body></html>